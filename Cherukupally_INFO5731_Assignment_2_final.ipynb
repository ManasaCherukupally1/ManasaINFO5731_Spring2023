{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManasaCherukupally1/Manasa_INFO5731_Spring2023/blob/main/Cherukupally_INFO5731_Assignment_2_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of a product (you can choose any porduct) on amazon.\n",
        "\n",
        "(2) Collect the top 10000 User Reviews of a film recently in 2023 or 2022 (you can choose any film) from IMDB.\n",
        "\n",
        "(3) Collect all the reviews of the top 1000 most popular software from [G2](https://www.g2.com/) or [Capterra](https://www.capterra.com/)\n",
        "\n",
        "(4) Collect the abstracts of the top 10000 research papers by using the query \"machine learning\", \"data science\", \"artifical intelligence\", or \"information extraction\" from [Semantic Scholar](https://www.semanticscholar.org).\n",
        "\n",
        "(5) Collect all the information of the 904 narrators in the [Densho Digital Repository](https://ddr.densho.org/narrators/).\n",
        "\n",
        "(6) Collect the top 10000 reddits by using a hashtag (you can use any hashtag) from Reddits.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AybhKVLctqgX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4239672-589d-4fab-973d-fa947f3d20e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       paperId                                              title  \\\n",
            "0     0036a6f72260c2b2963448c18d23601c06aa1405                          What is machine learning?   \n",
            "1     f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
            "2     46200b99c40e8586c8a0f588488ab6414119fb28  TensorFlow: A system for large-scale machine l...   \n",
            "3     9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  TensorFlow: Large-Scale Machine Learning on He...   \n",
            "4     f9c990b1b5724e50e5632b94fdb7484ece8a6ce7  Convolutional LSTM Network: A Machine Learning...   \n",
            "...                                        ...                                                ...   \n",
            "9994  b1a5cd85e046af32008c4bd137cf05b8dc7b5b43  Machine learning algorithms in context of intr...   \n",
            "9995  47ec7baa439deab14fe177e2da84a2f72cecdb2c  Learning informative point classes for the acq...   \n",
            "9996  4600f2b2a143b7bcdf5dae83e456649deb1908de  A Collection of Benchmark Datasets for Systema...   \n",
            "9997  956d14db8e6669f140f73129bb52dd8949bf2a6e  Cyber Hate Speech on Twitter: An Application o...   \n",
            "9998  e3e1f427b30a2de3ad13dc52dd752426991b96d2  Learning-based scheduling in a flexible manufa...   \n",
            "\n",
            "                                               abstract  \n",
            "0     To cite: Baloglu O, Latifi SQ, Nazha A. Arch D...  \n",
            "1     We present Fashion-MNIST, a new dataset compri...  \n",
            "2     TensorFlow is a machine learning system that o...  \n",
            "3     TensorFlow is an interface for expressing mach...  \n",
            "4     The goal of precipitation nowcasting is to pre...  \n",
            "...                                                 ...  \n",
            "9994  Design of efficient, accurate, and low complex...  \n",
            "9995  This paper proposes a set of methods for build...  \n",
            "9996                                               None  \n",
            "9997  The use of “Big Data” in policy and decision m...  \n",
            "9998  We develop a bilevel framework for scheduling ...  \n",
            "\n",
            "[9999 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "#Question 1\n",
        "#using semanticscholar API for scarping the articles from https://www.semanticscholar.org/\n",
        "\n",
        "import pandas as pd\n",
        "import warnings\n",
        "from semanticscholar import SemanticScholar\n",
        "\n",
        "\n",
        "# Ignoring warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "pd.set_option('display.width', None)\n",
        "\n",
        "# Initialization\n",
        "sem_sch = SemanticScholar()\n",
        "\n",
        "# Search articles using \"machine Learning\"\n",
        "res = sem_sch.search_paper('machine learning', fields=['title', 'abstract'])\n",
        "\n",
        "# Create dataframe\n",
        "df_paper = pd.DataFrame(columns=['paperId', 'title', 'abstract'])\n",
        "\n",
        "# Iterate through the search results and add each paper's information to the DataFrame\n",
        "count = 0\n",
        "for i in res:\n",
        "    count += 1\n",
        "    paper_info = {\n",
        "        'paperId': i.paperId,\n",
        "        'title': i.title,\n",
        "        'abstract': i.abstract\n",
        "    }\n",
        "    df_paper = df_paper.append(paper_info, ignore_index=True)\n",
        "\n",
        "    if count == 10000:\n",
        "        break\n",
        "\n",
        "# Print\n",
        "print(df_paper)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6-5F4Rqt_Yd"
      },
      "outputs": [],
      "source": [
        "#pip install semanticscholar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming.\n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vATjQNTY8buA",
        "outputId": "655de4f0-549f-4fb9-879c-42f7b1dbdaa4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       paperId                                              title  \\\n",
            "0     0036a6f72260c2b2963448c18d23601c06aa1405                          What is machine learning?   \n",
            "1     f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
            "2     46200b99c40e8586c8a0f588488ab6414119fb28  TensorFlow: A system for large-scale machine l...   \n",
            "3     9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  TensorFlow: Large-Scale Machine Learning on He...   \n",
            "4     f9c990b1b5724e50e5632b94fdb7484ece8a6ce7  Convolutional LSTM Network: A Machine Learning...   \n",
            "...                                        ...                                                ...   \n",
            "9993  5b7df1e9420c4692f53abdb756653feaf62e0b58  Network Accelerated Motion Estimation and Redu...   \n",
            "9994  b1a5cd85e046af32008c4bd137cf05b8dc7b5b43  Machine learning algorithms in context of intr...   \n",
            "9995  47ec7baa439deab14fe177e2da84a2f72cecdb2c  Learning informative point classes for the acq...   \n",
            "9997  956d14db8e6669f140f73129bb52dd8949bf2a6e  Cyber Hate Speech on Twitter: An Application o...   \n",
            "9998  e3e1f427b30a2de3ad13dc52dd752426991b96d2  Learning-based scheduling in a flexible manufa...   \n",
            "\n",
            "                                               abstract  \\\n",
            "0     To cite: Baloglu O, Latifi SQ, Nazha A. Arch D...   \n",
            "1     We present Fashion-MNIST, a new dataset compri...   \n",
            "2     TensorFlow is a machine learning system that o...   \n",
            "3     TensorFlow is an interface for expressing mach...   \n",
            "4     The goal of precipitation nowcasting is to pre...   \n",
            "...                                                 ...   \n",
            "9993  We introduce and validate a scalable retrospec...   \n",
            "9994  Design of efficient, accurate, and low complex...   \n",
            "9995  This paper proposes a set of methods for build...   \n",
            "9997  The use of “Big Data” in policy and decision m...   \n",
            "9998  We develop a bilevel framework for scheduling ...   \n",
            "\n",
            "                                       Cleaned_abstract  \n",
            "0     to cite baloglu o latifi sq nazha a arch di ch...  \n",
            "1     we present fashionmnist new dataset compris 28...  \n",
            "2     tensorflow machin learn system oper larg scale...  \n",
            "3     tensorflow interfac express machin learn algor...  \n",
            "4     the goal precipit nowcast predict futur rainfa...  \n",
            "...                                                 ...  \n",
            "9993  we introduc valid scalabl retrospect motion co...  \n",
            "9994  design effici accur low complex intrus detect ...  \n",
            "9995  thi paper propos set method build inform robus...  \n",
            "9997  the use big data polici decis make current top...  \n",
            "9998  we develop bilevel framework schedul circuit b...  \n",
            "\n",
            "[7425 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "#Question 2\n",
        "#pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "from textblob import Word\n",
        "import pandas as pd\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Function for preprocessing data\n",
        "# Function for preprocessing data\n",
        "def preprocess_data(abstract):\n",
        "    # Removing punctuation\n",
        "    abstract = abstract.str.replace('[^\\w\\s]', '')\n",
        "\n",
        "    # Removing stopwords\n",
        "    stop = stopwords.words('english')\n",
        "    abstract = abstract.apply(lambda x: \" \".join(x for x in x.split() if x not in stop))\n",
        "\n",
        "    # Remove numbers\n",
        "    abstract = abstract.apply(lambda x: \" \".join(x for x in x.split() if not x.isdigit()))\n",
        "\n",
        "    # Convert to lowercase\n",
        "    abstract = abstract.apply(lambda x: \" \".join(x.lower() for x in x.split()))\n",
        "\n",
        "    # Stemming\n",
        "    st = PorterStemmer()\n",
        "    abstract = abstract.apply(lambda x: \" \".join([st.stem(word) for word in x.split()]))\n",
        "\n",
        "    # Lemmatization\n",
        "    abstract = abstract.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
        "\n",
        "    return abstract\n",
        "\n",
        "df_paper = df_paper.dropna(subset=['abstract'])\n",
        "\n",
        "# Apply the preprocessing function to your DataFrame and store the results in a new column\n",
        "df_paper['Cleaned_abstract'] = preprocess_data(df_paper['abstract'])\n",
        "\n",
        "# Display the DataFrame with the cleaned text\n",
        "print(df_paper)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes:\n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QQKnPjPDHJHr",
        "outputId": "f62903fe-c455-4288-a976-b4dcfc893b3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       paperId                                              title  \\\n",
            "0     0036a6f72260c2b2963448c18d23601c06aa1405                          What is machine learning?   \n",
            "1     f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
            "2     46200b99c40e8586c8a0f588488ab6414119fb28  TensorFlow: A system for large-scale machine l...   \n",
            "3     9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  TensorFlow: Large-Scale Machine Learning on He...   \n",
            "4     f9c990b1b5724e50e5632b94fdb7484ece8a6ce7  Convolutional LSTM Network: A Machine Learning...   \n",
            "...                                        ...                                                ...   \n",
            "9993  5b7df1e9420c4692f53abdb756653feaf62e0b58  Network Accelerated Motion Estimation and Redu...   \n",
            "9994  b1a5cd85e046af32008c4bd137cf05b8dc7b5b43  Machine learning algorithms in context of intr...   \n",
            "9995  47ec7baa439deab14fe177e2da84a2f72cecdb2c  Learning informative point classes for the acq...   \n",
            "9997  956d14db8e6669f140f73129bb52dd8949bf2a6e  Cyber Hate Speech on Twitter: An Application o...   \n",
            "9998  e3e1f427b30a2de3ad13dc52dd752426991b96d2  Learning-based scheduling in a flexible manufa...   \n",
            "\n",
            "                                               abstract  \\\n",
            "0     To cite: Baloglu O, Latifi SQ, Nazha A. Arch D...   \n",
            "1     We present Fashion-MNIST, a new dataset compri...   \n",
            "2     TensorFlow is a machine learning system that o...   \n",
            "3     TensorFlow is an interface for expressing mach...   \n",
            "4     The goal of precipitation nowcasting is to pre...   \n",
            "...                                                 ...   \n",
            "9993  We introduce and validate a scalable retrospec...   \n",
            "9994  Design of efficient, accurate, and low complex...   \n",
            "9995  This paper proposes a set of methods for build...   \n",
            "9997  The use of “Big Data” in policy and decision m...   \n",
            "9998  We develop a bilevel framework for scheduling ...   \n",
            "\n",
            "                                       Cleaned_abstract  Noun (N)_POS_Count  Verb (V)_POS_Count  \\\n",
            "0     to cite baloglu o latifi sq nazha a arch di ch...                  74                   7   \n",
            "1     we present fashionmnist new dataset compris 28...                  29                   5   \n",
            "2     tensorflow machin learn system oper larg scale...                  68                  11   \n",
            "3     tensorflow interfac express machin learn algor...                  70                  10   \n",
            "4     the goal precipit nowcast predict futur rainfa...                  61                   3   \n",
            "...                                                 ...                 ...                 ...   \n",
            "9993  we introduc valid scalabl retrospect motion co...                  12                   3   \n",
            "9994  design effici accur low complex intrus detect ...                  66                  11   \n",
            "9995  thi paper propos set method build inform robus...                  50                   7   \n",
            "9997  the use big data polici decis make current top...                  73                  14   \n",
            "9998  we develop bilevel framework schedul circuit b...                  29                   6   \n",
            "\n",
            "      Adjective (Adj)_POS_Count  Adverb (Adv)_POS_Count  \\\n",
            "0                            19                       4   \n",
            "1                            10                       0   \n",
            "2                            18                       4   \n",
            "3                            19                       0   \n",
            "4                             9                       2   \n",
            "...                         ...                     ...   \n",
            "9993                          1                       0   \n",
            "9994                         15                       3   \n",
            "9995                         10                       2   \n",
            "9997                         25                       0   \n",
            "9998                          8                       0   \n",
            "\n",
            "                                   Noun Words_POS_Count  \\\n",
            "0     [(o, NN), (latifi, NN), (sq, NN), (arch, NN), ...   \n",
            "1     [(compris, NN), (imag, NN), (fashion, NN), (pr...   \n",
            "2     [(tensorflow, NN), (machin, NN), (learn, NN), ...   \n",
            "3     [(interfac, NN), (express, NN), (machin, NN), ...   \n",
            "4     [(goal, NN), (precipit, NN), (futur, NN), (rai...   \n",
            "...                                                 ...   \n",
            "9993  [(scalabl, NN), (retrospect, NN), (motion, NN)...   \n",
            "9994  [(design, NN), (intrus, NN), (detect, NN), (sy...   \n",
            "9995  [(paper, NN), (propos, NN), (method, NN), (bui...   \n",
            "9997  [(use, NN), (data, NNS), (polici, NN), (topic,...   \n",
            "9998  [(framework, NN), (schedul, NN), (circuit, NN)...   \n",
            "\n",
            "                                   Verb Words_POS_Count  \\\n",
            "0     [(cite, VB), (employ, VBP), (see, VB), (learn,...   \n",
            "1     [(present, VBP), (dataset, VBN), (set, VBN), (...   \n",
            "2     [(comput, VBD), (map, VBD), (known, VBN), (dev...   \n",
            "3     [(algorithm, VBZ), (rang, VBD), (card, VBP), (...   \n",
            "4        [(intens, VBZ), (examin, VBP), (predict, VBP)]   \n",
            "...                                                 ...   \n",
            "9993    [(introduc, VBP), (correct, VBP), (learn, VBP)]   \n",
            "9994  [(effici, VBZ), (detect, VB), (detect, VBP), (...   \n",
            "9995  [(set, VBN), (lie, VBZ), (pose, VBP), (charact...   \n",
            "9997  [(decis, VBP), (make, VBP), (led, VBD), (react...   \n",
            "9998  [(develop, VBP), (learn, VBP), (given, VBN), (...   \n",
            "\n",
            "                              Adjective Words_POS_Count  \\\n",
            "0     [(baloglu, JJ), (educ, JJ), (pract, JJ), (ed, ...   \n",
            "1     [(fashionmnist, JJ), (new, JJ), (grayscal, JJ)...   \n",
            "2     [(scale, JJ), (dataflow, JJ), (dataflow, JJ), ...   \n",
            "3     [(tensorflow, JJ), (algorithm, JJ), (tensorflo...   \n",
            "4     [(predict, JJ), (local, JJ), (short, JJ), (ver...   \n",
            "...                                                 ...   \n",
            "9993                                      [(valid, JJ)]   \n",
            "9994  [(low, JJ), (complex, JJ), (challeng, JJ), (de...   \n",
            "9995  [(thi, JJ), (robust, JJ), (featur, JJ), (local...   \n",
            "9997  [(big, JJ), (current, JJ), (woolwich, JJ), (pu...   \n",
            "9998  [(bilevel, JJ), (insert, JJ), (util, JJ), (ada...   \n",
            "\n",
            "                                 Adverb Words_POS_Count  \n",
            "0     [(ahead, RB), (often, RB), (there, RB), (bette...  \n",
            "1                                                    []  \n",
            "2     [(node, RB), (architectur, RB), (server, RB), ...  \n",
            "3                                                    []  \n",
            "4                        [(nowcast, RB), (better, RBR)]  \n",
            "...                                                 ...  \n",
            "9993                                                 []  \n",
            "9994          [(accur, RB), (not, RB), (algorithm, RB)]  \n",
            "9995                          [(well, RB), (noisi, RB)]  \n",
            "9997                                                 []  \n",
            "9998                                                 []  \n",
            "\n",
            "[7425 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "#3.1 Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import Counter\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "\n",
        "# Function to count POS tags\n",
        "def pos_tag_count(text):\n",
        "    # Tokenizing text\n",
        "    words = word_tokenize(text)\n",
        "\n",
        "    # POS tagging\n",
        "    pos_tagging = pos_tag(words)\n",
        "\n",
        "    # Initialize counters\n",
        "    noun_c = 0\n",
        "    verb_c = 0\n",
        "    adj_c = 0\n",
        "    adv_c = 0\n",
        "\n",
        "    # Lists to store word/tag pairs\n",
        "    noun_w = []\n",
        "    verb_w = []\n",
        "    adj_w = []\n",
        "    adv_w = []\n",
        "\n",
        "    # Define the POS tagging\n",
        "    noun_tagging = ['NN', 'NNS', 'NNP', 'NNPS']\n",
        "    verb_tagging = ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']\n",
        "    adj_tagging = ['JJ', 'JJR', 'JJS']\n",
        "    adv_tagging = ['RB', 'RBR', 'RBS']\n",
        "\n",
        "    # Count the parts of speech and extract word/tag pairs\n",
        "    for word, tag in pos_tagging:\n",
        "        if tag in noun_tagging:\n",
        "            noun_c += 1\n",
        "            noun_w.append((word, tag))\n",
        "        elif tag in verb_tagging:\n",
        "            verb_c += 1\n",
        "            verb_w.append((word, tag))\n",
        "        elif tag in adj_tagging:\n",
        "            adj_c += 1\n",
        "            adj_w.append((word, tag))\n",
        "        elif tag in adv_tagging:\n",
        "            adv_c += 1\n",
        "            adv_w.append((word, tag))\n",
        "\n",
        "    return pd.Series({\n",
        "        'Noun (N)': noun_c,\n",
        "        'Verb (V)': verb_c,\n",
        "        'Adjective (Adj)': adj_c,\n",
        "        'Adverb (Adv)': adv_c,\n",
        "        'Noun Words': noun_w,\n",
        "        'Verb Words': verb_w,\n",
        "        'Adjective Words': adj_w,\n",
        "        'Adverb Words': adv_w\n",
        "    })\n",
        "\n",
        "# Apply the function to the DataFrame and rename the columns\n",
        "result = df_paper['Cleaned_abstract'].apply(pos_tag_count)\n",
        "result.columns = result.columns.map(lambda x: f'{x}_POS_Count' if x != 0 else x)\n",
        "\n",
        "# Join the results to the original DataFrame\n",
        "df_paper = df_paper.join(result)\n",
        "\n",
        "# Print the DataFrame with the new columns\n",
        "print(df_paper)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiBUbCT4vonq",
        "outputId": "8dd3f179-2cfa-4e48-ab95-01f112cfca6f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       paperId                                              title  \\\n",
            "0     0036a6f72260c2b2963448c18d23601c06aa1405                          What is machine learning?   \n",
            "1     f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
            "2     46200b99c40e8586c8a0f588488ab6414119fb28  TensorFlow: A system for large-scale machine l...   \n",
            "3     9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  TensorFlow: Large-Scale Machine Learning on He...   \n",
            "4     f9c990b1b5724e50e5632b94fdb7484ece8a6ce7  Convolutional LSTM Network: A Machine Learning...   \n",
            "...                                        ...                                                ...   \n",
            "9993  5b7df1e9420c4692f53abdb756653feaf62e0b58  Network Accelerated Motion Estimation and Redu...   \n",
            "9994  b1a5cd85e046af32008c4bd137cf05b8dc7b5b43  Machine learning algorithms in context of intr...   \n",
            "9995  47ec7baa439deab14fe177e2da84a2f72cecdb2c  Learning informative point classes for the acq...   \n",
            "9997  956d14db8e6669f140f73129bb52dd8949bf2a6e  Cyber Hate Speech on Twitter: An Application o...   \n",
            "9998  e3e1f427b30a2de3ad13dc52dd752426991b96d2  Learning-based scheduling in a flexible manufa...   \n",
            "\n",
            "                                               abstract  \\\n",
            "0     To cite: Baloglu O, Latifi SQ, Nazha A. Arch D...   \n",
            "1     We present Fashion-MNIST, a new dataset compri...   \n",
            "2     TensorFlow is a machine learning system that o...   \n",
            "3     TensorFlow is an interface for expressing mach...   \n",
            "4     The goal of precipitation nowcasting is to pre...   \n",
            "...                                                 ...   \n",
            "9993  We introduce and validate a scalable retrospec...   \n",
            "9994  Design of efficient, accurate, and low complex...   \n",
            "9995  This paper proposes a set of methods for build...   \n",
            "9997  The use of “Big Data” in policy and decision m...   \n",
            "9998  We develop a bilevel framework for scheduling ...   \n",
            "\n",
            "                                       Cleaned_abstract  Noun (N)_POS_Count  Verb (V)_POS_Count  \\\n",
            "0     to cite baloglu o latifi sq nazha a arch di ch...                  74                   7   \n",
            "1     we present fashionmnist new dataset compris 28...                  29                   5   \n",
            "2     tensorflow machin learn system oper larg scale...                  68                  11   \n",
            "3     tensorflow interfac express machin learn algor...                  70                  10   \n",
            "4     the goal precipit nowcast predict futur rainfa...                  61                   3   \n",
            "...                                                 ...                 ...                 ...   \n",
            "9993  we introduc valid scalabl retrospect motion co...                  12                   3   \n",
            "9994  design effici accur low complex intrus detect ...                  66                  11   \n",
            "9995  thi paper propos set method build inform robus...                  50                   7   \n",
            "9997  the use big data polici decis make current top...                  73                  14   \n",
            "9998  we develop bilevel framework schedul circuit b...                  29                   6   \n",
            "\n",
            "      Adjective (Adj)_POS_Count  Adverb (Adv)_POS_Count  \\\n",
            "0                            19                       4   \n",
            "1                            10                       0   \n",
            "2                            18                       4   \n",
            "3                            19                       0   \n",
            "4                             9                       2   \n",
            "...                         ...                     ...   \n",
            "9993                          1                       0   \n",
            "9994                         15                       3   \n",
            "9995                         10                       2   \n",
            "9997                         25                       0   \n",
            "9998                          8                       0   \n",
            "\n",
            "                                   Noun Words_POS_Count  \\\n",
            "0     [(o, NN), (latifi, NN), (sq, NN), (arch, NN), ...   \n",
            "1     [(compris, NN), (imag, NN), (fashion, NN), (pr...   \n",
            "2     [(tensorflow, NN), (machin, NN), (learn, NN), ...   \n",
            "3     [(interfac, NN), (express, NN), (machin, NN), ...   \n",
            "4     [(goal, NN), (precipit, NN), (futur, NN), (rai...   \n",
            "...                                                 ...   \n",
            "9993  [(scalabl, NN), (retrospect, NN), (motion, NN)...   \n",
            "9994  [(design, NN), (intrus, NN), (detect, NN), (sy...   \n",
            "9995  [(paper, NN), (propos, NN), (method, NN), (bui...   \n",
            "9997  [(use, NN), (data, NNS), (polici, NN), (topic,...   \n",
            "9998  [(framework, NN), (schedul, NN), (circuit, NN)...   \n",
            "\n",
            "                                   Verb Words_POS_Count  \\\n",
            "0     [(cite, VB), (employ, VBP), (see, VB), (learn,...   \n",
            "1     [(present, VBP), (dataset, VBN), (set, VBN), (...   \n",
            "2     [(comput, VBD), (map, VBD), (known, VBN), (dev...   \n",
            "3     [(algorithm, VBZ), (rang, VBD), (card, VBP), (...   \n",
            "4        [(intens, VBZ), (examin, VBP), (predict, VBP)]   \n",
            "...                                                 ...   \n",
            "9993    [(introduc, VBP), (correct, VBP), (learn, VBP)]   \n",
            "9994  [(effici, VBZ), (detect, VB), (detect, VBP), (...   \n",
            "9995  [(set, VBN), (lie, VBZ), (pose, VBP), (charact...   \n",
            "9997  [(decis, VBP), (make, VBP), (led, VBD), (react...   \n",
            "9998  [(develop, VBP), (learn, VBP), (given, VBN), (...   \n",
            "\n",
            "                              Adjective Words_POS_Count  \\\n",
            "0     [(baloglu, JJ), (educ, JJ), (pract, JJ), (ed, ...   \n",
            "1     [(fashionmnist, JJ), (new, JJ), (grayscal, JJ)...   \n",
            "2     [(scale, JJ), (dataflow, JJ), (dataflow, JJ), ...   \n",
            "3     [(tensorflow, JJ), (algorithm, JJ), (tensorflo...   \n",
            "4     [(predict, JJ), (local, JJ), (short, JJ), (ver...   \n",
            "...                                                 ...   \n",
            "9993                                      [(valid, JJ)]   \n",
            "9994  [(low, JJ), (complex, JJ), (challeng, JJ), (de...   \n",
            "9995  [(thi, JJ), (robust, JJ), (featur, JJ), (local...   \n",
            "9997  [(big, JJ), (current, JJ), (woolwich, JJ), (pu...   \n",
            "9998  [(bilevel, JJ), (insert, JJ), (util, JJ), (ada...   \n",
            "\n",
            "                                 Adverb Words_POS_Count  \\\n",
            "0     [(ahead, RB), (often, RB), (there, RB), (bette...   \n",
            "1                                                    []   \n",
            "2     [(node, RB), (architectur, RB), (server, RB), ...   \n",
            "3                                                    []   \n",
            "4                        [(nowcast, RB), (better, RBR)]   \n",
            "...                                                 ...   \n",
            "9993                                                 []   \n",
            "9994          [(accur, RB), (not, RB), (algorithm, RB)]   \n",
            "9995                          [(well, RB), (noisi, RB)]   \n",
            "9997                                                 []   \n",
            "9998                                                 []   \n",
            "\n",
            "                                     Dependency_Parsing  \n",
            "0     [(to, aux, cite), (cite, advcl, nazha), (balog...  \n",
            "1     [(we, nsubj, present), (present, ccomp, catego...  \n",
            "2     [(tensorflow, npadvmod, map), (machin, compoun...  \n",
            "3     [(tensorflow, advcl, wwwtensorfloworg), (inter...  \n",
            "4     [(the, det, nowcast), (goal, compound, nowcast...  \n",
            "...                                                 ...  \n",
            "9993  [(we, nsubj, introduc), (introduc, ROOT, intro...  \n",
            "9994  [(design, compound, effici), (effici, nsubj, a...  \n",
            "9995  [(thi, prep, lie), (paper, compound, propos), ...  \n",
            "9997  [(the, det, decis), (use, nmod, decis), (big, ...  \n",
            "9998  [(we, nsubj, develop), (develop, ROOT, develop...  \n",
            "\n",
            "[7425 rows x 13 columns]\n"
          ]
        }
      ],
      "source": [
        "#3.2.1 Dependency Parsing\n",
        "\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the English spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to perform dependency parsing\n",
        "def dependency_parsing_tree(text):\n",
        "    doc = nlp(text)\n",
        "    # Extract the dependency relations\n",
        "    dependency_rel = [(token.text, token.dep_, token.head.text) for token in doc]\n",
        "    return dependency_rel\n",
        "\n",
        "# Apply the  function\n",
        "df_paper['Dependency_Parsing'] = df_paper['Cleaned_abstract'].apply(dependency_parsing_tree)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df_paper)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VVc-XE6U8OJ9"
      },
      "outputs": [],
      "source": [
        "#pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yOJzZ9568Kwd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "955c55019fe24ef99f05fd62e432d4ad",
            "51474735dd384bd5a7fcf8c8763c384e",
            "ccc45f1d0b0641a1801abae4ba9ab6c7",
            "4a27df77dd6844619e86cffb7bb988b7",
            "582f606f05604238950126a8f2753bb8",
            "70ccfc26aefe4f73896c461d3ec02be4",
            "6842461d47d441868103c89d172fddd8",
            "d86c3c99235942d68a180fbc048c7aee",
            "08394ff7db124021ada2b511fe3b250e",
            "e452be359a19465d99b3ac77b1a2cdb6",
            "55e9452fe81b4a05abf201cb1fb2bb4d"
          ]
        },
        "outputId": "7e97eb33-5c89-445d-b074-a474fdb3ebb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "955c55019fe24ef99f05fd62e432d4ad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: en (English):\n",
            "======================================\n",
            "| Processor    | Package             |\n",
            "--------------------------------------\n",
            "| tokenize     | combined            |\n",
            "| pos          | combined_charlm     |\n",
            "| constituency | ptb3-revised_charlm |\n",
            "======================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: constituency\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "(ROOT (S (S (S (S (S (VP (TO to) (VP (VB cite) (NP (FW baloglu) (FW o) (FW latifi) (FW sq) (FW nazha) (FW a) (FW arch) (FW di) (FW child) (FW educ) (FW pract) (FW ed) (FW epub) (FW ahead) (FW print) (FW plea) (FW includ) (NP (NML (FW day) (FW month)) (FW year)) (FW doi101136) (FW archdischild2020319415) (FW author) (FW employ) (NP (FW no) (FW commerci) (FW reus)))))) (VP (FW see) (NP (FW right) (FW permiss)) (FW publish) (ADJP (FW bmj)))) (NP (DT the) (FW term) (FW machin) (FW learn) (FW ml) (FW emerg) (FW often) (FW medic) (FW literatur) (FW there) (FW success) (FW clinic)) (VP (FW applic) (NP (FW ml) (FW specialti) (FW ophthalmolog) (FW radiolog) (FW lead) (FW way)) (PP (IN for) (NP (FW exampl))))) (NP (NP (FW ophthalmolog) (FW diagnosi)) (FW diabet) (FW retinopathi) (FW retinopathi) (FW prematur) (FW radiolog) (FW diagnosi) (NML (NML (NML (NN stroke) (NN cancer)) (NN digit)) (NN imag) (FW promis)) (S (NP (FW thi) (NN success)) (VP (VB expect) (S (VP (VB expand) (NP (NN medic) (FW disciplin)))))))) (VP (FW includ) (NP (FW gener) (NN paediatr) (FW subspecialti)) (FW therefor) (S (NP (NP (NML (NN healthcar) (NN practition)) (NN research)) (PP (IN like) (NP (NN benefit)))) (VP (VB get) (NML (JJ familiar) (NN ml) (NN terminolog) (NN order) (NN stay) (NN date) (ADJP (JJR better)))))) (VP (VB understand) (NP (NN ml) (NN research) (NN methodolog) (JJ applic) (NN medicin) (FW thi) (JJ brief) (NN review) (NN intend) (VP (NN introduct) (NP (NN ml) (NN associ) (NN terminolog) (NN review) (JJ select) (FW studi) (NN ml) (NN model) (NN paediatr) (NN literatur)))))))\n",
            "1\n",
            "(ROOT (S (NP (PRP we)) (VP (VBP present) (NP (JJ fashionmnist) (JJ new) (NML (NML (NN dataset) (NN compris)) (NML (NNP 28x28) (NNP grayscal) (NN imag) (NN fashion) (NN product))) (NN categori) (NN imag)) (PP (IN per) (NP (NN categori))) (S (NP (DT the) (NML (NML (NML (NML (ADJP (NN train) (NN set)) (NN imag) (NN test)) (FW set)) (FW imag) (FW fashionmnist)) (NN intend) (ADJP (FW serv) (JJ direct)) (NN dropin) (NN replac) (NN origin) (NN mnist)) (NML (NML (NML (NML (NML (NML (NN dataset) (NN benchmark)) (NN machin)) (NN learn)) (NN algorithm)) (NN share)) (NN imag) (NN size)) (NML (NN data) (NN format)) (NN structur) (NN train) (NN test)) (VP (VBD split) (NP (DT the) (NML (NML (NN dataset) (NN freeli)) (NN avail)) (NN http) (NN url)))))))\n",
            "2\n",
            "(ROOT (S (NP (GW tensorflow) (GW machin) (GW learn) (GW system) (NML (GW oper) (GW larg) (GW scale)) (GW heterogen) (GW environ) (GW tensorflow) (GW use) (GW dataflow) (GW graph) (GW repres) (NML (GW comput) (GW share)) (GW state) (GW oper) (GW mutat) (GW state)) (NP (GW it)) (VP (GW map) (GW node)) (GW dataflow) (GW graph) (PP (GW across) (NP (GW mani) (GW machin) (GW cluster))) (PP (GW within) (NP (GW machin))) (PP (GW across) (NP (NML (NML (GW multipl) (GW comput) (GW devic) (GW includ) (NML (NML (GW multicor) (GW cpu)) (FW generalpurpos))) (FW gpu) (FW customdesign) (FW asic) (FW known) (FW tensor) (GW process)) (GW unit) (FW tpu) (FW thi) (FW architectur))) (VP (FW give) (NP (FW flexibl) (NML (FW applic) (FW develop)) (NML (FW wherea) (FW previou)) (FW paramet) (FW server) (FW design) (NML (FW manag) (FW share)) (FW state) (FW built) (GW system) (FW tensorflow) (FW enabl) (S (VP (GW develop) (NP (NML (FW experi) (GW novel)) (FW optim) (GW train) (FW algorithm)))) (FW tensorflow) (FW support) (FW varieti) (FW applic) (FW focu) (FW train) (FW infer) (ADJP (JJ deep) (JJ neural) (NN network)) (VP (NN sever) (NP (NP (NNP googl) (NML (NML (FW servic) (NN use)) (FW tensorflow)) (NML (NN product) (NN releas)) (NN opensourc) (NN project)) (VP (VB becom) (NP (JJ wide) (NN use) (NN machin)))) (S (VP (VB learn) (NP (NN research)) (PP (IN in) (NP (NML (NN paper) (NN describ)) (NML (FW tensorflow) (NN dataflow) (NN model)) (NN demonstr) (NN compel)))) (VP (VB perform) (NP (FW tensorflow) (FW achiev)) (S (VP (NN sever) (NP (JJ realworld) (NN applic)))))))))))\n",
            "3\n",
            "(ROOT (NP (ADJP (NP (FW tensorflow) (FW interfac) (FW express) (FW machin) (FW learn) (FW algorithm)) (FW implement) (NML (FW execut) (FW algorithm))) (FW a) (FW comput) (FW express) (FW use) (FW tensorflow) (FW execut) (FW littl) (FW chang) (FW wide) (FW varieti) (FW heterogen) (FW system) (FW rang) (FW mobil) (FW devic) (FW phone) (FW tablet) (FW largescal) (FW distribut) (FW system) (NP (NML (NML (NML (FW hundr) (FW machin)) (FW thousand)) (FW comput) (FW devic)) (FW gpu) (FW card)) (S (NP (DT the) (FW system) (FW flexibl) (NML (FW use) (FW express)) (FW wide) (FW varieti) (FW algorithm) (FW includ) (FW train) (FW infer) (FW algorithm) (JJ deep) (JJ neural) (NN network) (NN model) (NN use) (NN conduct) (NN research) (FW deploy) (NP (FW machin) (NML (FW learn) (NN system)) (NN product)) (NML (NML (ADJP (FW across) (FW dozen)) (FW area)) (FW comput) (FW scienc) (FW field)) (FW includ) (NP (FW speech) (FW recognit) (FW comput) (FW vision) (FW robot) (FW inform)))) (FW retriev) (NML (NML (FW natur) (FW languag)) (FW process)) (FW geograph) (FW inform) (NML (FW extract) (FW comput) (FW drug) (FW discoveri)) (FW thi) (FW paper) (FW describ) (S (NP (FW tensorflow) (FW interfac) (FW implement) (FW interfac) (VBN built) (FW googl)) (NP (DT the) (FW tensorflow) (FW api)) (VP (FW refer) (S (VP (FW implement) (NP (FW releas) (FW opensourc) (FW packag) (FW apach) (FW licens) (FW novemb)) (ADJP (FW avail) (ADD wwwtensorfloworg))))))))\n",
            "4\n",
            "(ROOT (S (NP (ADJP (NP (DT the) (FW goal) (FW precipit) (FW nowcast) (FW predict) (NP (FW futur) (FW rainfal)) (FW intens) (NML (FW local) (FW region)) (ADJP (FW rel) (FW short) (FW period)) (FW time) (FW veri)) (FW previou) (FW studi) (FW examin) (NP (FW crucial) (FW challeng) (NML (FW weather) (FW forecast)) (FW problem))) (FW machin) (FW learn) (NP (FW perspect)) (PP (FW in) (NP (NML (FW paper) (FW formul)) (FW precipit) (FW nowcast) (FW spatiotempor) (FW sequenc) (FW forecast) (FW problem) (FW input)))) (VP (FW predict) (NP (FW target) (FW spatiotempor) (FW sequenc)) (PP (FW by) (NP (FW extend) (NML (NML (FW fulli) (FW connect)) (FW lstm) (FW fclstm) (FW convolut) (FW structur) (FW inputtost)) (FW statetost) (FW transit) (FW propos) (FW convolut) (FW lstm) (FW convlstm) (FW use) (FW build) (FW endtoend) (FW trainabl) (FW model) (FW precipit) (FW nowcast) (FW problem) (FW experi) (FW show) (FW convlstm) (FW network) (FW captur) (FW spatiotempor) (FW correl) (ADVP (RBR better)) (VP (VB consist) (NP (NN outperform) (FW fclstm) (FW stateoftheart) (FW oper) (FW rover) (NN algorithm) (FW precipit) (FW nowcast))))))))\n",
            "5\n",
            "(ROOT (S (S (VP (FW understand) (S (NP (NML (FW machin) (FW learningprobabilist) (FW machin) (FW learninghandson) (FW machin) (FW learn) (FW scikitlearn) (FW kera) (FW tensorflowfundament) (FW machin) (FW learningreinforc) (FW learn) (FW second)) (FW editiondeep) (FW learningintroduc) (FW machin) (FW learningfound) (FW data) (FW sciencefundament) (FW deep) (FW learningintellig) (FW systemsmachin) (FW learn) (FW refinedan) (VP (FW introduct) (NP (FW deep) (FW reinforc))) (NP (FW learningdeep) (FW learn) (FW fundament))) (FW theori) (FW applicationsdeep) (FW learningdeep) (FW learn) (FW coder) (FW fastai) (FW pytorchmachin) (FW learninga) (FW brief) (FW introduct) (NP (FW machin) (FW learn)))) (NP (FW engineersel) (FW causal) (FW inferencefundament) (FW machin) (FW learn) (FW predict) (NP (FW data) (FW analyt)) (FW second) (FW editionmachin) (FW learn) (FW clinic))) (FW neurosciencelearn) (FW deep) (FW architectur) (FW aiartifici) (FW intelligencestatist) (FW foundat) (NP (FW data)) (FW scienceth) (FW mathemat) (FW foundat) (FW learn) (FW machinesfound) (NP (FW machin) (FW learningmachin) (FW learn)) (FW foundationsboostingth) (FW algorithm) (FW foundat) (NML (FW differenti) (FW privacymathemat)) (FW machin) (FW learningfound) (FW rule) (FW learningdeep) (FW learn) (FW pytorchneur) (FW network) (FW learningdeep) (FW learn) (FW illustratedfound) (NP (FW deep) (FW reinforc)) (NP (FW learningfound) (FW machin) (FW learn) (FW second) (FW editionimbalanc)) (FW learningfound) (FW knowledg) (NP (FW acquisitionon) (FW path) (FW aimachin) (FW learn) (FW theoret) (FW foundat) (FW practic) (FW applicationsartifici) (FW intellig) (FW machin) (FW learn) (NP (NN fundament)))))\n",
            "6\n",
            "(ROOT (S (NP (NML (NN machin) (NN learn) (NN address)) (NN question)) (VP (VB build) (NP (NP (NML (NN comput) (NN improv)) (NN automat)) (VP (NN experi) (NP (PRP it)))) (NP (NP (CD one) (NN today)) (SBAR (ADJP (ADJP (NN rapidli) (NN grow)) (NML (NN technic) (NN field)) (NN lie)) (VP (NN intersect) (NML (NML (NML (NN comput) (NN scienc)) (NN statist)) (NN core) (NN artifici) (NN intellig) (NN data) (NN scienc)) (NP (JJ recent) (NN progress)) (NN machin) (S (VP (NN learn) (VP (VBN driven))) (VP (VB develop) (NP (NP (NML (NML (JJ new) (NN learn)) (NN algorithm)) (NN theori)) (NN ongo) (NN explos) (NN avail) (NN onlin) (NNS data) (JJ lowcost) (NN comput) (S (NP (DT the) (NN adopt) (NN dataintens) (NN machinelearn) (NN method)) (VP (VBD found) (PP (IN throughout) (NP (NML (NN scienc) (NN technolog)) (NN commerc) (NP (NN lead) (FW evidencebas)) (VP (NN decisionmak) (PP (IN across) (NP (NML (NN mani) (NN walk)) (NN life))) (PP (JJ includ) (NP (NML (NML (NN health) (NN care)) (NN manufactur)) (NN educ) (NML (NML (NN financi) (NN model)) (NN polic)) (NN market)))))))))))))))))\n",
            "7\n",
            "(ROOT (S (S (S (S (NP (NN today)) (NP (FW weben)) (VP (FW delug) (NP (NN electron) (NN data))) (FW call) (FW autom) (FW method) (FW data) (FW analysi) (FW machin) (FW learn) (FW provid) (S (VP (VB develop) (NP (NN method) (NML (NML (NML (NML (FW automat) (NN detect)) (NN pattern)) (NN data)) (NN use)) (FW uncov) (NN pattern))))) (VP (FW predict) (NP (FW futur) (NN data)))) (NP (NP (FW thi) (NN textbook)) (FW offer) (FW comprehens) (FW selfcontain) (FW introduct) (NN field) (FW machin) (FW learn) (NN base) (FW unifi) (NN probabilist) (NN approach) (S (NP (DT the) (NN coverag) (NN combin) (NN breadth) (NN depth)) (VP (VBP offer) (NML (NML (JJ necessari) (NN background)) (NN materi) (NN topic)))))) (NP (FW probabl) (NN optim) (JJ linear) (NN algebra)) (ADVP (RB well)) (VP (NN discus) (S (NP (JJ recent) (NN develop) (NN field))) (PP (NN includ) (NP (NP (NML (NN condit) (JJ random) (NN field)) (NN l1) (JJ regular) (JJ deep) (VB learn) (NP (NP (DT the) (NN book)) (VP (VBN written) (S (VP (NN inform) (NP (NP (NN access) (NN style)) (FW complet) (NML (NML (FW pseudocod) (NN import)) (NN algorithm))))))) (NML (ADJP (ADJP (DT all) (FW topic)) (JJ copious)) (NML (NML (NN illustr) (NN color)) (NN imag)) (NN work) (FW exampl))) (VP (VBN drawn) (S (NP (NML (NML (NML (NML (JJ applic) (NN domain)) (NN biolog)) (NN text) (NN process)) (NN comput) (NN vision)) (NN robot)) (ADJP (ADJP (RB rather) (JJ provid)) (NML (NN cookbook) (NN differ)) (FW heurist) (NN method) (NN book) (NN stress))))))) (FW principl) (FW modelbas) (VP (NN approach) (ADVP (RB often)) (VP (VB use) (NP (FW languag) (NML (JJ graphic) (NN model)) (FW specifi) (NN model) (FW concis) (NN intuit) (FW way)) (ADJP (RB almost) (NN model)) (FW describ) (FW implement) (FW matlab) (FW softwar) (FW packagepmtk) (FW probabilist) (FW model) (FW toolkitthat) (FW freeli) (FW avail) (FW onlin) (S (NP (DT the) (NN book) (FW suitabl) (FW upperlevel) (FW undergradu) (FW introductorylevel) (NML (FW colleg) (FW math)) (NN background)) (VP (VB begin) (NP (NN graduat) (NN student))))))))\n",
            "8\n",
            "(ROOT (SINV (S (PP (IN with) (S (S (S (NP (NP (JJ widespread) (NN use) (NN artifici) (NN intellig) (POS ai) (NN system)) (ADJP (JJ applic) (NP (JJ everyday) (NML (JJ live) (NN account)) (NML (JJ fair) (NN gain)) (NML (JJ signific) (NN import) (NN design)) (NN engin) (NN system) (FW ai) (NN system)))) (VP (FW use) (NP (ADJP (FW mani) (FW sensit)) (FW environ)))) (VP (VB make) (NP (NN import) (NN lifechang) (NN decis)) (SBAR (FW thu) (S (NP (JJ crucial) (NN ensur) (NN decis)) (VP (VB reflect) (NP (JJ discriminatori) (NN behavior)) (PP (IN toward) (NP (NP (JJ certain) (NN group) (ADJP (JJ popul) (RBR more) (JJ recent)) (NN work)) (VP (VB develop) (NP (NML (NN tradit) (NN machin) (NN learn)) (NML (NML (JJ deep) (NN learn)) (NN address)) (ADJP (NN challeng) (NN differ)) (NN subdomain)) (PP (IN with) (NP (NML (NML (NN commerci) (NN system)) (NN research) (JJ becom) (NN awar) (NN bias)) (NN applic))))))))))) (VP (VB contain) (NP (NN attempt) (NN address)) (PP (IN in) (NP (NN survey) (NN investig)))))) (VP (VB differ)) (S (NP (JJ realworld) (JJ applic) (VBN shown) (NN bias) (JJ variou) (NN way) (NN list)) (VP (VBP differ) (NP (NN sourc) (NN bias)))) (VP (VBP affect) (S (VP (VBZ ai) (NN applic) (SBAR (S (NP (PRP we)) (VP (VBP creat) (NP (NML (NN taxonomi) (JJ fair) (NN definit)) (NN machin)) (S (VP (NN learn) (NP (NN research) (S (VP (NN defin) (S (VP (VB avoid) (VP (VB exist) (SBAR (S (NP (NN bia)) (VP (VBZ ai)))))))))))))))))) (NP (NP (NN system)) (PP (IN in) (S (VP (NN addit) (NP (NN examin)) (S (VP (VB differ) (NP (NN domain) (NN subdomain)) (FW ai) (NN show) (NN research) (NN observ) (NN regard) (NP (NP (JJ unfair) (NN outcom) (NML (NN stateoftheart) (NN method)) (NN way)) (FW tri) (NN address)) (ADVP (PRP$ there)) (ADVP (RB still)) (NP (NML (FW mani) (FW futur)) (ADJP (ADJP (JJ direct) (NN solut)) (VBN taken)) (NML (NN mitig) (NN problem)) (NN bia))))))))) (VBZ ai) (NP (NP (NN system)) (SBAR (S (NP (PRP we)) (VP (VBP hope) (S (VP (NN survey) (NP (NN motiv) (NN research)) (NN tackl) (NP (NN issu)) (PP (IN near) (NP (FW futur) (FW observ))))))))) (VP (VB exist) (NP (NN work) (NN respect) (NN field)))))\n",
            "9\n",
            "(ROOT (NP (FW scikitlearn) (FW python) (FW modul) (FW integr) (FW wide) (FW rang) (FW stateoftheart) (FW machin) (FW learn) (FW algorithm) (FW mediumscal) (FW supervis) (FW unsupervis) (FW problem) (FW thi) (FW packag) (FW focus) (FW bring) (S (NML (NML (FW machin) (FW learn)) (FW nonspecialist) (FW use) (FW generalpurpos) (FW highlevel) (FW languag) (FW emphasi) (FW put) (ADJP (FW ea) (FW use) (FW perform)) (FW document) (FW api)) (VP (FW consist))) (NP (FW it)) (VP (FW minim) (VP (FW depend) (FW distribut) (FW simplifi) (FW bsd) (FW licens) (FW encourag) (FW use) (FW academ) (FW commerci) (FW set) (FW sourc) (FW code) (FW binari) (NN document) (NN download) (ADD httpscikitlearnsourceforgenet)))))\n",
            "10\n",
            "(ROOT (S (S (NP (PRP we)) (VP (VBP present) (NP (NP (NML (NML (JJ open) (NN graph)) (FW benchmark)) (FW ogb) (NN diver)) (VP (FW set) (NP (FW challeng) (FW realist) (FW benchmark) (FW dataset)))))) (FW facilit) (NP (ADJP (FW scalabl) (FW robust)) (FW reproduc)) (FW graph) (NP (FW machin) (FW learn)) (FW ml) (FW research) (FW ogb) (FW dataset) (NP (NP (NML (FW largescal) (FW million)) (FW node) (FW billion)) (FW edg) (FW encompass)) (NML (NML (NML (FW multipl) (FW import)) (FW graph)) (FW ml)) (NML (NN task) (NN cover)) (NN diver) (FW rang) (NN domain) (FW rang) (NML (NML (JJ social) (FW inform)) (NN network)) (NML (FW biolog) (NN network)) (NML (FW molecular) (FW graph)) (FW sourc) (FW code) (FW ast) (FW knowledg) (FW graph) (PP (FW for) (NP (NML (FW dataset) (FW provid)) (NML (NML (FW unifi) (FW evalu)) (NN protocol)) (FW use) (FW meaning) (NP (FW applicationspecif) (FW data) (FW split)) (FW evalu) (FW metric))) (PP (IN in) (NP (ADJP (FW addit) (NN build)) (NN dataset))) (ADVP (RB also)) (VP (VB perform) (NP (FW extens) (FW benchmark) (FW experi) (FW dataset)) (NP (PRP$ our) (ADJP (FW experi) (FW suggest)) (NML (FW ogb) (FW dataset)) (FW present) (FW signific) (FW challeng) (FW scalabl) (FW largescal) (FW graph) (FW outofdistribut) (FW gener) (FW realist) (NML (FW data) (FW split)) (FW indic) (NML (NML (NN fruit) (FW opportun)) (FW futur) (FW research) (FW final) (FW ogb) (FW provid)) (NP (FW autom) (FW endtoend)) (FW graph) (FW ml) (NML (FW pipelin) (FW simplifi) (FW standard) (NN process)) (NN graph) (NML (NML (FW data) (NN load)) (FW experiment)) (FW setup) (FW model) (FW evalu) (FW ogb) (FW regularli) (FW updat) (NP (NML (FW welcom) (FW input)) (FW commun) (FW ogb) (FW dataset) (FW well) (FW data) (FW loader) (FW evalu) (NN script) (NML (FW baselin) (NN code)) (NML (NN leaderboard) (FW publicli) (NN avail)) (NN http) (NN url))))))\n",
            "11\n",
            "(ROOT (S (NP (NP (DT the) (NML (NML (NN use) (NN machin)) (NN learn) (NN algorithm))) (ADJP (JJ frequent) (NN involv) (NN care) (NN tune))) (VP (VB learn) (NP (NML (NN paramet) (NN model)) (NN hyperparamet) (FW unfortun) (VP (NN tune) (ADVP (RB often)))) (SBAR (S (S (NML (NP (JJ black) (NN art)) (NN requir) (NN expert) (NN experi) (NN rule) (NN thumb) (FW sometim) (NN bruteforc) (NN search) (ADVP (RB there)) (ADVP (RB therefor)) (S (NP (NML (JJ great) (NN appeal) (NN automat) (NN approach)) (NN optim)) (VP (VB perform) (PP (VBN given) (NP (NP (NML (NML (NN learn) (NN algorithm)) (NN problem)) (NN hand)) (PP (IN in) (NML (NML (NML (NN work) (NN consid)) (NN problem)) (NN framework)))))))) (NN bayesian) (NN optim) (NN learn) (NN algorithm) (NN gener)) (VP (VB perform) (NP (NML (NN model) (NN sampl)) (NML (NN gaussian) (NN process)) (NN gp)))) (S (NP (PRP we)) (VP (VBP show) (S (NP (JJ certain) (NML (NML (NML (NN choic) (NN natur) (NN gp)) (NN type)) (NN kernel) (NN treatment)) (NN hyperparamet) (NN play) (JJ crucial) (NN role)) (VP (VB obtain) (NP (NP (NP (NP (JJ good) (NN optim) (NN achiev) (NN expertlevel)) (NN perform)) (SBAR (S (NP (PRP we)) (VP (VBP describ) (NP (NP (JJ new) (NN algorithm)) (VP (NN take) (NP (NN account)))))))) (NP (NML (NML (NML (JJ variabl) (NN cost)) (NN durat) (NN learn) (NN algorithm)) (NN experi) (NN leverag) (NN presenc) (JJ multipl) (NN core) (JJ parallel) (NN experiment)) (SBAR (S (NP (PRP we)) (VP (VBP show) (S (NP (FW propos) (NN algorithm) (NN improv) (FW previou) (FW automat) (FW procedur) (NN reach)) (VP (VB surpass) (NP (NML (NML (JJ human) (NN expertlevel)) (NN optim) (NN mani) (NN algorithm)) (VP (NN includ) (NP (NML (NML (NP (NN latent) (NN dirichlet)) (NN alloc)) (NN structur)) (NML (NN svm) (NN convolut)) (JJ neural) (NN network)))))))))))))))))))\n",
            "12\n",
            "(ROOT (S (NP (NN today)) (NP (NN artifici) (NN intellig)) (ADVP (RB still)) (VP (VBP face) (S (NP (CD two) (JJ major) (NN challeng) (CD one) (FW industri) (NNS data)) (VP (VBP exist) (SBAR (NN form) (S (NP (NN isol) (NN island)) (NP (NP (DT the) (NN strengthen) (NN data) (NN privaci) (NN secur)) (SBAR (S (NP (PRP we)) (VP (VBP propos) (S (NP (ADJP (JJ possibl) (NN solut) (NN challeng) (NN secur)) (NNP feder)) (VP (VB learn) (SBAR (IN beyond) (S (NP (NP (NNP federatedlearn) (NN framework)) (JJ first)) (FW propos) (ADJP (NNP googl) (FW introduc) (NN comprehens) (NN secur) (NN federatedlearn) (NN framework) (AFX includ) (NN horizont) (NNP feder) (VB learn) (JJ vertic) (S (S (NNP feder) (VP (VB learn) (NP (NN feder) (NN transfer)))) (NN learn)) (SBAR (S (NP (PRP we)) (VP (VBP provid) (S (NP (JJ definit) (NN architectur) (JJ applic) (NML (JJ federatedlearn) (NN framework)) (JJ provid) (JJ comprehens) (NN survey) (NN exist) (NN work) (NN subject) (PP (IN in) (S (NP (NN addit) (VP (NN propos) (S (VP (NN build) (NP (NN data) (NN network)) (PP (IN among) (NP (NML (NML (JJ organ) (NN base)) (NN feder) (NN mechan) (NN effect)) (NN solut))))))) (VP (VBP allow) (NP (NN knowledg) (NN share)) (PP (IN without) (NP (NN compromis) (NN user) (NN privaci)))))))))))))))))))))))))))\n",
            "13\n",
            "(ROOT (S (S (NP (FW feder) (FW learn)) (ADVP (RB also)) (VP (VBN known) (NP (ADJP (FW collabor) (FW learn)) (FW machin) (FW learn) (FW techniqu) (FW train) (FW algorithm)) (PP (IN without) (NML (FW transfer) (FW data))))) (FW sampl) (PP (FW across) (NP (NML (FW numer) (FW decentr)) (FW edg) (FW devic) (FW server))) (NP (FW thi) (FW strategi) (FW differ) (FW standard) (JJ central) (FW machin) (FW learn) (FW techniqu) (NP (NML (JJ local) (FW dataset)) (FW upload)) (NML (FW singl) (NN server)) (FW well) (FW tradit) (FW decentr) (ADJP (FW altern) (JJ frequent) (FW presum)) (JJ local) (FW data) (FW sampl) (S (NP (FW uniformli) (FW distribut) (FW feder) (FW learn) (S (VP (VB allow) (S (NP (NN sever) (NN actor) (NN collabor) (VB develop) (ADJP (AFX singl) (JJ robust)) (NN machin) (NN learn) (NN model))) (PP (IN without) (NP (NN share) (NNS data)))))) (VP (VBP allow) (NP (NML (NML (JJ crucial) (NN issu)) (NN data) (NN privaci)) (NML (NN data) (NN secur)) (NML (NN data) (NN access)) (NML (NML (NML (NML (JJ right) (NN access)) (NN heterogen)) (NN data)) (NN address)) (NN defenc) (NN telecommun) (NN internet) (NN thing)) (NN pharmaceut) (NN industri) (NN sector) (NN applic))))))\n",
            "14\n",
            "(ROOT (PP (IN from) (NP (VP (VB publish) (NML (NN classifi) (NN system) (NN play)) (JJ major) (NN role)) (FW machin) (FW learn) (FW knowledgebas) (NN system) (FW ross) (FW quinlan) (FW work) (FW id3) (FW c45) (FW wide) (FW acknowledg) (VP (VBN made) (NP (JJ signific) (NN contribut) (VB develop) (NP (FW thi) (NN book)) (FW complet) (FW guid) (NP (NML (NML (FW c45) (NN system)) (NN implement)) (FW c) (FW unix) (FW environ)) (S (NP (PRP it)) (VP (VB contain) (NP (NML (NML (NML (NN comprehens) (NN guid) (NN system)) (NN use)) (NN sourc) (NN code)) (NN line) (NN implement) (NN note)) (S (NP (DT the) (NML (NML (NN sourc) (NN code)) (FW sampl)) (NN dataset)) (ADVP (RB also)) (VP (FW avail) (NP (NP (FW 35inch) (FW floppi) (FW diskett) (FW sun) (FW workstat) (NML (FW c45) (NN start) (FW larg)) (FW set) (NN case)) (VP (VB belong) (VP (VBN known) (SBAR (NP (S (NN class) (NP (DT the) (NN case))) (PP (FW describ) (S (NP (NN mixtur) (FW nomin) (FW numer) (FW properti) (NN scrutin) (NN pattern)) (VP (VB allow) (S (NML (NML (NN class) (NN reliabl)) (NN discrimin)) (NP (DT these) (NML (NML (NN pattern) (JJ express)) (NN model) (NN form)) (NN decis) (NML (NML (NML (NN tree) (NN set)) (NN ifthen)) (NN rule)))))))) (S (VP (NN use) (S (VP (NN classifi) (NP (NML (JJ new) (NN case)) (NN emphasi))))) (VP (VB make) (S (NP (NN model)) (VP (VB understand) (ADVP (RB well)) (VP (VB accur) (NP (DT the) (NML (NN system) (NN appli)) (NN success) (NN task))))) (SBAR (IN involv) (S (NP (NP (QP (CD ten) (CD thousand)) (NN case)) (VP (NN describ) (NP (NP (NML (NN hundr) (NN properti)) (NP (DT the) (NN book) (NN start)) (NML (NN simpl) (NN core)) (NN learn) (NN method)) (VP (VB show) (NP (NML (NML (NN elabor) (VB extend)) (NN deal) (JJ typic) (NN problem) (NN miss)) (NN data)))))) (VP (VB hit) (NP (NN advantag) (NN disadvantag)) (S (NML (NML (AFX c45) (NN approach)) (NN discus) (NN illustr) (NN sever) (NN case) (FW studi) (FW thi) (NN book) (NN softwar) (NN interest)) (VP (VB develop) (S (NP (NN classificationbas) (NML (NML (NN intellig) (NN system)) (NN student)) (NN machin)) (VP (NN learn) (NP (NN expert) (NN system)) (ADVP (FW cours))))))))))))))))))))))))\n",
            "15\n",
            "(ROOT (S (NP (NP (DT a) (NN machin) (NN learn) (NN system)) (ADJP (JJ becom) (NP (NN ubiquit) (NN surg) (NN interest)) (VP (NN interpret) (S (VP (NN machin) (NN learn) (NN system) (NN provid) (NP (NN explan)) (S (VP (NN output) (NP (DT these) (NN explan))))))))) (ADVP (RB often)) (VP (VB use) (S (NP (NN qualit) (NML (NN ass) (NN criterion)) (NN safeti) (NN nondiscrimin) (NN howev)) (VP (VB despit) (NP (NP (NN interest) (NN interpret) (FW littl) (NN consensu)) (VP (VB interpret) (NP (NN machin) (VB learn) (NN measur)) (PP (IN in) (NP (NN posit) (NN paper))) (S (ADVP (RB first)) (VP (VB defin) (S (VP (VB interpret) (VP (NN describ) (S (VP (VB interpret) (NP (NN need))))))))) (ADVP (RB next)) (VP (VB suggest) (SBAR (S (NP (NP (NP (NN taxonomi) (NN rigor)) (FW evalu) (NN expo) (JJ open) (NN question)) (PP (IN toward) (NP (NN rigor) (NN scienc)))) (VP (VB interpret) (NP (NN machin) (NN learn)))))))))))))\n",
            "16\n",
            "(ROOT (S (S (VP (FW interpret) (NP (FW machin) (FW learn))) (FW becom) (NP (JJ popular) (NN research))) (ADJP (ADJP (JJ direct) (JJ deep)) (JJ neural) (NN network)) (FW dnn) (FW becom) (FW power) (FW applic) (FW mainstream) (FW yet) (NP (FW dnn) (FW remain)) (ADJP (JJ difficult) (FW understand)) (ADJP (FW test) (FW concept)) (FW activ) (FW vector) (FW tcav) (FW kim) (FW et) (FW al) (FW approach) (FW interpret) (FW dnn) (FW humanfriendli) (FW way) (FW recent) (FW receiv) (FW signific) (FW attent) (FW machin) (FW learn) (FW commun) (NP (FW the) (FW tcav) (FW algorithm) (FW achiev) (FW degre) (FW global) (FW interpret) (FW dnn) (FW humandefin) (FW concept) (FW explan) (FW thi) (FW project) (S (VP (FW introduc) (NP (FW robust) (ADJP (FW tcav) (FW build)) (FW tcav) (FW experiment)) (FW determin) (JJS best) (FW practic) (FW method) (S (S (NP (DT the) (ADJP (FW object) (FW robust)) (ADJP (FW tcav) (FW make)) (FW tcav) (FW consist) (FW reduc) (FW varianc) (FW tcav) (FW score) (FW distribut) (FW increas)) (FW cav) (FW tcav) (FW score) (FW resist) (FW perturb) (NP (FW a) (NML (ADJP (FW differ) (FW mean) (FW method)) (FW cav) (FW gener) (FW determin) (RBS best) (FW practic) (FW achiev) (FW object)) (NML (FW mani) (FW area)) (FW tcav) (FW process) (FW explor))))) (FW includ) (NP (NML (NML (FW cav) (FW visual) (FW low)) (FW dimens)) (ADJP (FW neg) (FW class))) (VP (FW select) (NP (FW activ) (FW perturb)) (NP (FW direct) (FW cav) (FW final) (FW threshold) (FW techniqu) (FW consid) (FW remov) (FW nois) (FW tcav) (FW score) (NP (FW thi) (NN project) (NN step) (ADJP (JJ direct) (FW make)) (S (NP (FW tcav) (FW alreadi) (NN impact) (NN algorithm)) (VP (VB interpret) (NP (NN reliabl) (NN use) (NN practition)))))))))))\n",
            "17\n",
            "(ROOT (S (NP (S (NP (GW machin) (GW learn) (GW ml) (GW model) (GW eg) (JJ deep) (NN neural) (GW network)) (GW dnn) (NML (GW vulner) (GW adversari)) (GW exampl) (GW malici) (GW input) (GW modifi) (GW yield) (FW erron) (GW model)) (GW output)) (VP (VP (GW appear) (S (ADJP (AFX unmodifi) (JJ human) (FW observ)) (ADJP (GW potenti) (GW attack)) (PP (GW includ) (NP (NP (FW malici) (NN content)) (PP (IN like) (NP (NML (FW malwar) (FW identifi) (FW legitim) (NN control)) (FW vehicl) (NN behavior))))))) (CC yet) (VP (VB exist) (NP (NP (NP (FW adversari) (FW exampl) (NN attack) (FW requir) (NN knowledg) (CC either) (NN model) (NN intern) (NN train) (NNS data)) (SBAR (S (NP (PRP we)) (VP (VBP introduc) (ADJP (RB first) (FW practic)))))) (FW demonstr) (FW attack) (FW control) (FW remot) (FW host) (FW dnn) (FW knowledg) (FW inde) (FW capabl) (FW blackbox) (FW adversari) (FW observ) (FW label) (VBN given) (FW dnn) (S (NP (VBN chosen) (NN input) (SBAR (S (NP (PRP$ our) (NN attack) (FW strategi)) (VP (VB consist) (S (VP (NN train) (NP (NML (NML (JJ local) (NN model)) (NN substitut) (NN target) (NN dnn) (NN use) (NN input) (FW synthet) (FW gener) (FW adversari)) (NN label) (NN target) (NN dnn)))))) (SBAR (S (NP (PRP we)) (VP (VBP use) (NP (JJ local) (NML (NML (JJ substitut) (NN craft)) (NN adversari)) (NN exampl))))))) (VP (VB find) (NP (NML (NN misclassifi) (NN target)) (NN dnn)) (S (VP (TO to) (VP (VB perform) (NP (NP (JJ realworld) (NML (NML (JJ properlyblind) (NN evalu) (NN attack)) (FW dnn) (NN host) (NN metamind) (FW onlin)) (ADJP (JJ deep) (NN learn)) (NN api)) (SBAR (S (NP (PRP we)) (VP (VBP find) (NML (FW dnn) (FW misclassifi) (FW adversari) (FW exampl) (NN craft) (FW substitut) (NP (NP (PRP we)) (VP (FW demonstr) (FW gener) (FW applic) (FW strategi) (FW mani) (FW ml) (FW techniqu) (NN conduct) (NN attack) (NN model) (NN host) (NNP amazon) (NNP googl) (NN use) (NN logist) (NN regress) (NN substitut) (SBAR (S (NP (PRP they)) (VP (VBP yield) (NP (NP (JJ adversari) (NN exampl) (NN misclassifi) (NN amazon) (NNP googl) (NN rate)) (SBAR (S (NP (PRP we)) (ADVP (RB also)) (VP (VBP find) (SBAR (S (NP (NP (NP (NML (NN blackbox) (NN attack strategi)) (NN capabl) (NN evad)) (NN defens) (FW strategi)) (JJ previous)) (VP (VBD found) (S (VP (VB make) (NP (JJ adversari) (NN exampl) (NN craft)) (S (ADJP (JJR harder))))))))))))))))))))))))))))))))\n",
            "18\n",
            "(ROOT (NP (ADJP (FW hogg) (FW r)) (FW v) (FW mckean) (FW j) (FW w) (FW craig) (FW a) (FW t) (FW introduct) (FW mathemat) (FW statist) (FW 6th) (FW ed) (FW upper) (FW saddl) (FW river) (FW nj) (FW prenticehal) (FW lohr) (FW s) (FW l) (FW sampl) (FW design) (FW analysi) (FW pacif) (FW grove) (FW ca) (FW duxburi) (FW press) (FW mittelhamm) (FW r) (FW c) (FW mathemat) (FW statist) (FW econom) (FW busi) (FW administr) (FW new) (FW york) (FW springer) (FW särndal) (FW ce) (FW swensson) (FW b) (FW wretman) (FW j) (FW modelassist) (FW survey) (FW sampl) (JJ new) (NNP york) (FW springer)))\n",
            "19\n",
            "(ROOT (S (S (NP (PRP we)) (VP (VBP quantit) (NP (NML (NML (NML (NML (NN investig) (NML (NML (NN machin) (NN learn)) (NN model))) (NN leak)) (VP (NN inform) (NP (NN individu) (NN data) (NN record)))) (NN train)) (SBAR (S (NP (PRP we)) (VP (VBP focu) (ADJP (NML (JJ basic) (NN membership) (NN infer) (NN attack)) (PP (VBN given) (NP (NML (NML (NN data) (NN record)) (NN blackbox) (NN access) (NN model) (NN determin) (NML (NN record) (NN model)) (NN train) (NN dataset)) (SBAR (S (VP (TO to) (VP (VB perform) (NML (NN membership) (NN infer) (NN target) (NN model))))))))))))))) (VP (VB make) (S (NP (NML (NML (NN adversari) (NN use)) (NN machin)) (NN learn) (NN train)) (VP (NN infer) (NP (NN model) (S (VP (NN recogn) (S (VP (NN differ) (NML (NN target) (NN model))))) (VP (NN predict) (NP (NP (NML (NN input) (NN train) (NN versu)) (NP (NN input) (NN train))) (SBAR (S (NP (PRP we)) (VP (VBP empir) (S (VP (FW evalu) (VP (NN infer) (NP (FW techniqu) (NN classif) (NN model) (NN train)))) (VP (FW commerci) (FW machin)) (VP (NN learn) (ADJP (NN servic) (FW provid))) (S (NP (NNP googl) (NNP amazon)) (VP (NN use) (NP (JJ realist) (SBAR (VP (NML (NML (NML (NN dataset) (NN classif)) (NN task)) (NN includ)) (NP (NP (NN hospit) (NN discharg) (NN dataset)) (SBAR (WHNP (WP$ whose) (NN membership)) (S (VP (NN sensit) (NP (NN privaci) (NN perspect))) (VP (VBP show) (NP (NP (NN model) (NN vulner) (NN membership)) (VP (NN infer) (NP (NN attack))))))))) (S (NP (PRP we)) (VP (VBP investig) (NP (NN factor) (FW influenc) (FW leakag) (FW evalu) (FW mitig) (FW strategi)))))))))))))))))))))\n",
            "20\n",
            "(ROOT (S (PP (IN from) (S (VP (VB publish) (NP (NNP thi) (NN book))))) (VP (VB bring) (NP (NP (JJ togeth) (NN inform)) (NML (NML (NN tutori) (NN fashion) (NN comput)) (NN techniqu)) (NML (NML (NML (NN mathemat) (NN tool)) (NN research)) (NN result)))) (NN enabl) (NP (NP (NML (NML (NN student) (NN practition)) (NN appli)) (NML (NML (NN genet) (NN algorithm)) (NN problem)) (NML (NN mani) (NN field)) (NML (JJ major) (NN concept)) (NML (NML (FW illustr) (VBN run)) (NN exampl)) (NML (NML (JJ major) (NN algorithm)) (NN illustr))) (NP (NNP pascal) (NN comput) (NN program))) (NP (DT no) (NML (NML (JJ prior) (NN knowledg)) (NNP ga) (NN genet) (NN assum)) (NML (NML (JJ minimum) (NN comput)) (NN program)) (NN mathemat) (NN background) (NN requir))))\n",
            "21\n",
            "(ROOT (S (S (S (S (NP (S (NML (GW tradit) (GW lithiumion) (GW liion) (GW batteri) (GW state) (GW health) (GW soh)) (GW estim) (GW methodolog) (GW focus) (GW estim) (NP (GW present) (GW cell) (GW capac))) (GW provid) (ADJP (GW suffici) (VP (GW inform) (NML (GW determin) (GW cell)))) (GW lifecycl) (GW stage) (GW valu) (GW secondlif) (GW use) (GW quantifi) (GW underli) (GW degrad) (GW mode) (GW caus) (NP (FW capac) (NN fade)) (FW give) (NML (NN insight) (GW electrochem) (GW state) (GW cell) (FW provid) (GW detail) (GW health) (GW inform) (FW remain) (FW activ) (FW materi) (GW lithium) (FW inventori) (FW howev) (JJ current) (GW physicsbas) (GW method) (GW degrad) (GW diagnost) (GW requir) (GW longterm) (GW cycl) (GW data) (FW comput) (FW expens) (S (VP (VB deploy) (NP (JJ local) (NN devic)) (S (PP (TO to) (S (VP (VB improv) (PP (IN upon) (NP (NP (JJ current) (NN method)) (GW propos))))))))) (GW extens) (NN test) (NP (CD two) (GW lightweight) (GW physicsinform) (GW machin) (GW learn) (GW method) (GW onlin)) (GW estim) (NP (GW capac) (GW batteri) (GW cell) (GW diagnos)) (GW primari) (FW degrad) (GW mode) (S (VP (GW use) (NP (NN limit) (NML (FW earlylif) (GW experiment))))))) (VP (FW degrad) (NP (NN data)) (PP (IN to) (S (VP (FW enabl) (ADJP (FW latelif) (S (VP (FW predict) (NP (FW eg) (NN year)) (PP (IN without) (NP (NP (FW use) (NML (FW latelif) (FW experiment)) (FW data) (FW method)) (FW train) (FW use) (NML (FW simul) (FW data)) (FW physicsbas))))))))))) (FW halfcel) (FW model) (FW earlylif) (FW eg) (FW month) (FW degrad) (FW data) (FW obtain) (NP (FW cycl) (FW test)) (S (NP (FW the) (FW propos) (FW method) (FW comprehens) (NML (NML (NML (NML (FW evalu) (FW use)) (FW data)) (FW longterm)) (FW year)) (FW cycl) (FW experi) (FW implantablegrad) (FW liion) (FW cell) (FW cycl) (NP (FW two) (FW temperatur) (FW crate) (FW result) (FW fourfold)) (FW crossvalid) (FW studi) (FW show) (FW propos) (FW physicsinform) (NP (FW machin) (FW learn) (FW model)) (FW capabl) (FW improv) (FW estim) (NML (FW accuraci) (FW cell)) (FW capac) (FW state) (FW three) (FW primari) (FW degrad) (FW mode) (NML (FW compar) (FW pure)) (FW datadriven) (FW approach)) (VP (FW addit) (NP (ADJP (FW work) (FW provid)) (FW insight) (FW role))))) (FW temperatur) (NP (FW crate) (FW cell))) (FW degrad) (FW loss) (FW lithiat) (FW activ) (FW materi) (FW one) (FW electrod) (FW lam) (NP (NP (FW pene) (FW loss)) (FW lithium) (FW due) (FW solid)) (FW electrolyt) (FW interfac) (ADJP (ADJP (FW sei) (FW growth)) (FW pure)) (FW lli) (FW total) (FW loss) (FW lithium) (FW inventori) (FW quantifi) (FW lii) (FW paramet) (FW total) (FW lam) (FW pene) (NP (FW the) (FW lam) (FW paramet) (FW use)) (PP (FW throughout) (ADJP (NP (FW studi) (FW use)) (FW quantifi))) (FW delithi) (FW lam) (FW wherea) (FW lithiat) (FW lam) (FW quantifi) (NP (FW linear) (FW combin) (FW lam) (FW lii) (FW practic) (FW increas) (FW lli) (FW result) (FW accumul) (FW parasit) (FW reaction) (FW cell) (FW contribut) (NP (FW lithium) (FW inventori) (FW loss)) (FW eg) (FW sei) (FW growth) (FW electrolyt) (FW decomposit) (NP (FW delamin) (FW lithiat) (FW electrod) (FW materi)))))\n",
            "22\n",
            "(ROOT (S (NP (NP (NN problem) (NN consid) (NN function) (GW fx1) (GW x2) (FW x1) (NN x)) (PP (IN at) (NP (NN point) (NN xk)))) (FW t) (VP (NN find) (NML (NML (NN gradient) (NN descent)) (NN direct))) (NN b) (NP (FW xk1) (JJ exact) (NN line) (NN search) (NN gradient) (NN descent) (NN direct) (FW c) (FW newton) (FW direct) (FW xk1) (NML (JJ exact) (NN line) (NN search)) (FW newton) (JJ direct) (NN problem) (VP (FW consid) (VP (FW follow) (NP (NP (NML (FW quadrat) (NN function)) (FW fx) (FW xqx) (FW bx) (FW assum) (FW q) (FW symmetr) (NN posit)) (VP (FW definit) (SBAR (WHNP (WDT what)) (FRAG (VP (NN gradient) (NN fx)))))))))))\n",
            "23\n",
            "(ROOT (S (NP (NP (DT the) (NN machin) (NN learn) (NN field)) (SBAR (S (VP (NN briefli)) (VP (VB defin) (S (NP (NN enabl) (NN comput)) (VP (VB make) (NP (NN success)))))))) (VP (VB predict) (S (VP (VB use) (NP (JJ past) (NN experi) (NN exhibit) (NN impress)) (S (VP (VB develop) (NML (NP (JJ recent) (NN help)) (NML (JJ rapid) (NN increas)) (NN storag) (NML (NML (NN capac) (NN process)) (NN power) (FW comput) (NN togeth)) (FW mani) (FW disciplin) (NP (NN machin) (NN learn) (NN method)) (ADJP (JJ wide) (VB employ) (S (VP (NN bioinformat) (NP (NP (DT the) (NN difficulti) (NN cost)) (SBAR (SBAR (NP (NP (NN biolog) (NN analys)) (VP (VBN led) (S (VP (VB develop) (NP (NML (NN sophist) (NN machin)) (NN learn) (NN approach)))))) (S (NP (ADJP (JJ applic) (NN area)) (PP (IN in) (NP (NN chapter) (NML (JJ first) (NN review)) (NN fundament) (NN concept) (NN machin)))) (VP (VB learn) (S (NP (NN featur) (NN ass) (FW unsupervis) (FW versu) (FW supervis)) (VP (VB learn) (NP (NN type) (NN classif))))))) (ADVP (RB then)) (VP (VB point) (NML (NML (JJ main) (NN issu)) (NN design) (NN machin)) (S (VP (VB learn) (ADVP (NN experi)))))))) (VP (VB perform) (S (NP (JJ evalu) (JJ final) (NN introduc) (NN supervis)) (VP (VB learn) (NP (NN method)))))))))))))))\n"
          ]
        }
      ],
      "source": [
        "#3.2.2 Constituency Parsing\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk import word_tokenize, pos_tag\n",
        "from collections import Counter\n",
        "import stanza\n",
        "\n",
        "#initialize\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
        "\n",
        "\n",
        "# Define a function for constituency parsing\n",
        "def constituency_parsing_tree(text,index):\n",
        "    doc = nlp(text)\n",
        "    constituency_res = []\n",
        "\n",
        "    for sent in doc.sentences:\n",
        "        print(index)\n",
        "        print(sent.constituency)\n",
        "\n",
        "# Apply the function\n",
        "#df_paper['Cleaned_abstract'].apply(constituency_parsing_tree)\n",
        "\n",
        "for index, abstract in enumerate(df_paper['Cleaned_abstract']):\n",
        "    constituency_parsing_tree(abstract, index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pip install stanfordnlp"
      ],
      "metadata": {
        "id": "dYZiwEWybwfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3.3 Named Entity Recognition\n",
        "import spacy\n",
        "import pandas as pd\n",
        "\n",
        "# Load the English spaCy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Function to extract and count entities\n",
        "def extract_and_count_entities(text):\n",
        "    doc = nlp(text)\n",
        "    entity_counts = {\n",
        "        'PERSON': 0,\n",
        "        'ORG': 0,\n",
        "        'LOC': 0,\n",
        "        'PRODUCT': 0,\n",
        "        'DATE': 0,\n",
        "    }\n",
        "    entity_words = {\n",
        "        'PERSON': [],\n",
        "        'ORG': [],\n",
        "        'LOC': [],\n",
        "        'PRODUCT': [],\n",
        "        'DATE': [],\n",
        "    }\n",
        "\n",
        "    for ent in doc.ents:\n",
        "        if ent.label_ in entity_counts:\n",
        "            entity_counts[ent.label_] += 1\n",
        "            entity_words[ent.label_].append(ent.text)\n",
        "\n",
        "    return entity_counts, entity_words\n",
        "\n",
        "# Apply the function\n",
        "df_paper['Entity_Counts'], df_paper['Entity_Words'] = zip(*df_paper['Cleaned_abstract'].apply(extract_and_count_entities))\n",
        "\n",
        "# Create separate columns\n",
        "entity_types = ['PERSON', 'ORG', 'LOC', 'PRODUCT', 'DATE']\n",
        "for entity_type in entity_types:\n",
        "    df_paper[entity_type + '_Words'] = df_paper['Entity_Words'].apply(lambda x: x[entity_type])\n",
        "\n",
        "# Drop 'Entity_Words'\n",
        "df_paper = df_paper.drop(columns='Entity_Words')\n",
        "\n",
        "# Print\n",
        "print(df_paper)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXWX4YhWUcTS",
        "outputId": "bf18d4b8-7848-4825-ae16-bf6ce98348d3"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                       paperId                                              title  \\\n",
            "0     0036a6f72260c2b2963448c18d23601c06aa1405                          What is machine learning?   \n",
            "1     f9c602cc436a9ea2f9e7db48c77d924e09ce3c32  Fashion-MNIST: a Novel Image Dataset for Bench...   \n",
            "2     46200b99c40e8586c8a0f588488ab6414119fb28  TensorFlow: A system for large-scale machine l...   \n",
            "3     9c9d7247f8c51ec5a02b0d911d1d7b9e8160495d  TensorFlow: Large-Scale Machine Learning on He...   \n",
            "4     f9c990b1b5724e50e5632b94fdb7484ece8a6ce7  Convolutional LSTM Network: A Machine Learning...   \n",
            "...                                        ...                                                ...   \n",
            "9993  5b7df1e9420c4692f53abdb756653feaf62e0b58  Network Accelerated Motion Estimation and Redu...   \n",
            "9994  b1a5cd85e046af32008c4bd137cf05b8dc7b5b43  Machine learning algorithms in context of intr...   \n",
            "9995  47ec7baa439deab14fe177e2da84a2f72cecdb2c  Learning informative point classes for the acq...   \n",
            "9997  956d14db8e6669f140f73129bb52dd8949bf2a6e  Cyber Hate Speech on Twitter: An Application o...   \n",
            "9998  e3e1f427b30a2de3ad13dc52dd752426991b96d2  Learning-based scheduling in a flexible manufa...   \n",
            "\n",
            "                                               abstract  \\\n",
            "0     To cite: Baloglu O, Latifi SQ, Nazha A. Arch D...   \n",
            "1     We present Fashion-MNIST, a new dataset compri...   \n",
            "2     TensorFlow is a machine learning system that o...   \n",
            "3     TensorFlow is an interface for expressing mach...   \n",
            "4     The goal of precipitation nowcasting is to pre...   \n",
            "...                                                 ...   \n",
            "9993  We introduce and validate a scalable retrospec...   \n",
            "9994  Design of efficient, accurate, and low complex...   \n",
            "9995  This paper proposes a set of methods for build...   \n",
            "9997  The use of “Big Data” in policy and decision m...   \n",
            "9998  We develop a bilevel framework for scheduling ...   \n",
            "\n",
            "                                       Cleaned_abstract  Noun (N)_POS_Count  Verb (V)_POS_Count  \\\n",
            "0     to cite baloglu o latifi sq nazha a arch di ch...                  74                   7   \n",
            "1     we present fashionmnist new dataset compris 28...                  29                   5   \n",
            "2     tensorflow machin learn system oper larg scale...                  68                  11   \n",
            "3     tensorflow interfac express machin learn algor...                  70                  10   \n",
            "4     the goal precipit nowcast predict futur rainfa...                  61                   3   \n",
            "...                                                 ...                 ...                 ...   \n",
            "9993  we introduc valid scalabl retrospect motion co...                  12                   3   \n",
            "9994  design effici accur low complex intrus detect ...                  66                  11   \n",
            "9995  thi paper propos set method build inform robus...                  50                   7   \n",
            "9997  the use big data polici decis make current top...                  73                  14   \n",
            "9998  we develop bilevel framework schedul circuit b...                  29                   6   \n",
            "\n",
            "      Adjective (Adj)_POS_Count  Adverb (Adv)_POS_Count  \\\n",
            "0                            19                       4   \n",
            "1                            10                       0   \n",
            "2                            18                       4   \n",
            "3                            19                       0   \n",
            "4                             9                       2   \n",
            "...                         ...                     ...   \n",
            "9993                          1                       0   \n",
            "9994                         15                       3   \n",
            "9995                         10                       2   \n",
            "9997                         25                       0   \n",
            "9998                          8                       0   \n",
            "\n",
            "                                   Noun Words_POS_Count  \\\n",
            "0     [(o, NN), (latifi, NN), (sq, NN), (arch, NN), ...   \n",
            "1     [(compris, NN), (imag, NN), (fashion, NN), (pr...   \n",
            "2     [(tensorflow, NN), (machin, NN), (learn, NN), ...   \n",
            "3     [(interfac, NN), (express, NN), (machin, NN), ...   \n",
            "4     [(goal, NN), (precipit, NN), (futur, NN), (rai...   \n",
            "...                                                 ...   \n",
            "9993  [(scalabl, NN), (retrospect, NN), (motion, NN)...   \n",
            "9994  [(design, NN), (intrus, NN), (detect, NN), (sy...   \n",
            "9995  [(paper, NN), (propos, NN), (method, NN), (bui...   \n",
            "9997  [(use, NN), (data, NNS), (polici, NN), (topic,...   \n",
            "9998  [(framework, NN), (schedul, NN), (circuit, NN)...   \n",
            "\n",
            "                                   Verb Words_POS_Count  \\\n",
            "0     [(cite, VB), (employ, VBP), (see, VB), (learn,...   \n",
            "1     [(present, VBP), (dataset, VBN), (set, VBN), (...   \n",
            "2     [(comput, VBD), (map, VBD), (known, VBN), (dev...   \n",
            "3     [(algorithm, VBZ), (rang, VBD), (card, VBP), (...   \n",
            "4        [(intens, VBZ), (examin, VBP), (predict, VBP)]   \n",
            "...                                                 ...   \n",
            "9993    [(introduc, VBP), (correct, VBP), (learn, VBP)]   \n",
            "9994  [(effici, VBZ), (detect, VB), (detect, VBP), (...   \n",
            "9995  [(set, VBN), (lie, VBZ), (pose, VBP), (charact...   \n",
            "9997  [(decis, VBP), (make, VBP), (led, VBD), (react...   \n",
            "9998  [(develop, VBP), (learn, VBP), (given, VBN), (...   \n",
            "\n",
            "                              Adjective Words_POS_Count  \\\n",
            "0     [(baloglu, JJ), (educ, JJ), (pract, JJ), (ed, ...   \n",
            "1     [(fashionmnist, JJ), (new, JJ), (grayscal, JJ)...   \n",
            "2     [(scale, JJ), (dataflow, JJ), (dataflow, JJ), ...   \n",
            "3     [(tensorflow, JJ), (algorithm, JJ), (tensorflo...   \n",
            "4     [(predict, JJ), (local, JJ), (short, JJ), (ver...   \n",
            "...                                                 ...   \n",
            "9993                                      [(valid, JJ)]   \n",
            "9994  [(low, JJ), (complex, JJ), (challeng, JJ), (de...   \n",
            "9995  [(thi, JJ), (robust, JJ), (featur, JJ), (local...   \n",
            "9997  [(big, JJ), (current, JJ), (woolwich, JJ), (pu...   \n",
            "9998  [(bilevel, JJ), (insert, JJ), (util, JJ), (ada...   \n",
            "\n",
            "                                 Adverb Words_POS_Count  \\\n",
            "0     [(ahead, RB), (often, RB), (there, RB), (bette...   \n",
            "1                                                    []   \n",
            "2     [(node, RB), (architectur, RB), (server, RB), ...   \n",
            "3                                                    []   \n",
            "4                        [(nowcast, RB), (better, RBR)]   \n",
            "...                                                 ...   \n",
            "9993                                                 []   \n",
            "9994          [(accur, RB), (not, RB), (algorithm, RB)]   \n",
            "9995                          [(well, RB), (noisi, RB)]   \n",
            "9997                                                 []   \n",
            "9998                                                 []   \n",
            "\n",
            "                                     Dependency_Parsing  \\\n",
            "0     [(to, aux, cite), (cite, advcl, nazha), (balog...   \n",
            "1     [(we, nsubj, present), (present, ccomp, catego...   \n",
            "2     [(tensorflow, npadvmod, map), (machin, compoun...   \n",
            "3     [(tensorflow, advcl, wwwtensorfloworg), (inter...   \n",
            "4     [(the, det, nowcast), (goal, compound, nowcast...   \n",
            "...                                                 ...   \n",
            "9993  [(we, nsubj, introduc), (introduc, ROOT, intro...   \n",
            "9994  [(design, compound, effici), (effici, nsubj, a...   \n",
            "9995  [(thi, prep, lie), (paper, compound, propos), ...   \n",
            "9997  [(the, det, decis), (use, nmod, decis), (big, ...   \n",
            "9998  [(we, nsubj, develop), (develop, ROOT, develop...   \n",
            "\n",
            "                                          Entity_Counts  \\\n",
            "0     {'PERSON': 3, 'ORG': 1, 'LOC': 0, 'PRODUCT': 0...   \n",
            "1     {'PERSON': 1, 'ORG': 0, 'LOC': 0, 'PRODUCT': 0...   \n",
            "2     {'PERSON': 1, 'ORG': 1, 'LOC': 0, 'PRODUCT': 0...   \n",
            "3     {'PERSON': 1, 'ORG': 0, 'LOC': 0, 'PRODUCT': 0...   \n",
            "4     {'PERSON': 0, 'ORG': 1, 'LOC': 0, 'PRODUCT': 1...   \n",
            "...                                                 ...   \n",
            "9993  {'PERSON': 0, 'ORG': 0, 'LOC': 0, 'PRODUCT': 0...   \n",
            "9994  {'PERSON': 2, 'ORG': 0, 'LOC': 0, 'PRODUCT': 0...   \n",
            "9995  {'PERSON': 1, 'ORG': 0, 'LOC': 0, 'PRODUCT': 0...   \n",
            "9997  {'PERSON': 2, 'ORG': 2, 'LOC': 0, 'PRODUCT': 0...   \n",
            "9998  {'PERSON': 0, 'ORG': 2, 'LOC': 0, 'PRODUCT': 0...   \n",
            "\n",
            "                                           PERSON_Words  \\\n",
            "0     [latifi sq nazha, emerg, methodolog applic med...   \n",
            "1                                             [compris]   \n",
            "2                                      [varieti applic]   \n",
            "3      [chang wide varieti heterogen system rang mobil]   \n",
            "4                                                    []   \n",
            "...                                                 ...   \n",
            "9993                                                 []   \n",
            "9994                               [appli kdd99, kdd99]   \n",
            "9995                                [compris multivalu]   \n",
            "9997                 [drummer lee, spatialbas classifi]   \n",
            "9998                                                 []   \n",
            "\n",
            "                                              ORG_Words LOC_Words PRODUCT_Words        DATE_Words  \n",
            "0                                    [disciplin includ]        []            []  [day month year]  \n",
            "1                                                    []        []            []                []  \n",
            "2                                           [heterogen]        []            []         [flexibl]  \n",
            "3                                                    []        []            []         [flexibl]  \n",
            "4                                [lstm fclstm convolut]        []        [veri]                []  \n",
            "...                                                 ...       ...           ...               ...  \n",
            "9993                                                 []        []            []                []  \n",
            "9994                                                 []        []            []                []  \n",
            "9995                                                 []        []            []                []  \n",
            "9997  [justifi discrimin social, the applic polici d...        []            []                []  \n",
            "9998                 [surfac mount technolog, electron]        []            []                []  \n",
            "\n",
            "[7425 rows x 19 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constituency parsing tree and Dependency parsing tree are two techniques used in analyzing the gramatical structure of the sentences and the relationship between them. Constituency parsing also known as phrase structure parsing is used to divide the sentences in grammatical phrases such as noun,verb and prepositional phrases. it provides the hierarchical representation of the grammatical structure of the sentences. Dependency parsing focus on the relationship between the words in the sentences. sentences are represented as a tree of words. each word is related to other with grammatical relationship between them.\n",
        "\n",
        "In the below code for constituency parsing \"This assignment\" is noun phrase \"is tough\" is verb phrase and \"is\" is the root phrase.\n",
        "\n",
        "for dependency parsing \"This\" is determiner of \"Assignment\". Assignment is nominal subject of \"is\".\"is\" is the root.\"tough\" is adjective complement of is\n"
      ],
      "metadata": {
        "id": "LZn6UtcSVcxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "# Load spaCy NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "example_sentence = \"This assignment is tough\"\n",
        "\n",
        "# dependency parsing\n",
        "print(\"Dependency Parsing\")\n",
        "dependency_tree = dependency_parsing_tree(example_sentence)\n",
        "for token, dep, head in dependency_tree:\n",
        "    print(f\"{token} -{dep}-> {head}\")\n",
        "\n",
        "import stanza\n",
        "\n",
        "#initialize\n",
        "nlp = stanza.Pipeline(lang='en', processors='tokenize,pos,constituency')\n",
        "\n",
        "# constituency parsing\n",
        "print(\"\\nConstituency Parsing\")\n",
        "constituency_parsing_tree(example_sentence, 1)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "b0f677baa87c477db4e354feb97b02af",
            "ec038a87124d4c008e6c9f1a8a1d1ed2",
            "da886821f9bd48708461d95d8349fd21",
            "17abce1fd4d2464faee509790239f23a",
            "0e14d8e4abe448d99c48854c6cd30e8f",
            "3dd237c1fb7f4913918a7d74bc729202",
            "98327ed075194e01b71a10e9078379df",
            "bc4184f15f2444ee825a0fbe3b649f9c",
            "9dba7c70d0074811b4a60c035f937963",
            "f4ceab97c7b44361ac0575c679d142e4",
            "652647e98e6242138333147b0dc0bdb8"
          ]
        },
        "id": "JB3QfcYBE7YH",
        "outputId": "395ad826-6542-4995-92c3-988e9115353c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dependency Parsing\n",
            "This -det-> assignment\n",
            "assignment -nsubj-> is\n",
            "is -ROOT-> is\n",
            "tough -acomp-> is\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json:   0%|   …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b0f677baa87c477db4e354feb97b02af"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:stanza:Loading these models for language: en (English):\n",
            "======================================\n",
            "| Processor    | Package             |\n",
            "--------------------------------------\n",
            "| tokenize     | combined            |\n",
            "| pos          | combined_charlm     |\n",
            "| constituency | ptb3-revised_charlm |\n",
            "======================================\n",
            "\n",
            "INFO:stanza:Using device: cpu\n",
            "INFO:stanza:Loading: tokenize\n",
            "INFO:stanza:Loading: pos\n",
            "INFO:stanza:Loading: constituency\n",
            "INFO:stanza:Done loading processors!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Constituency Parsing\n",
            "1\n",
            "(ROOT (S (NP (DT This) (NN assignment)) (VP (VBZ is) (ADJP (JJ tough)))))\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "955c55019fe24ef99f05fd62e432d4ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51474735dd384bd5a7fcf8c8763c384e",
              "IPY_MODEL_ccc45f1d0b0641a1801abae4ba9ab6c7",
              "IPY_MODEL_4a27df77dd6844619e86cffb7bb988b7"
            ],
            "layout": "IPY_MODEL_582f606f05604238950126a8f2753bb8"
          }
        },
        "51474735dd384bd5a7fcf8c8763c384e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70ccfc26aefe4f73896c461d3ec02be4",
            "placeholder": "​",
            "style": "IPY_MODEL_6842461d47d441868103c89d172fddd8",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: "
          }
        },
        "ccc45f1d0b0641a1801abae4ba9ab6c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d86c3c99235942d68a180fbc048c7aee",
            "max": 45749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08394ff7db124021ada2b511fe3b250e",
            "value": 45749
          }
        },
        "4a27df77dd6844619e86cffb7bb988b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e452be359a19465d99b3ac77b1a2cdb6",
            "placeholder": "​",
            "style": "IPY_MODEL_55e9452fe81b4a05abf201cb1fb2bb4d",
            "value": " 367k/? [00:00&lt;00:00, 6.36MB/s]"
          }
        },
        "582f606f05604238950126a8f2753bb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70ccfc26aefe4f73896c461d3ec02be4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6842461d47d441868103c89d172fddd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d86c3c99235942d68a180fbc048c7aee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08394ff7db124021ada2b511fe3b250e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e452be359a19465d99b3ac77b1a2cdb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55e9452fe81b4a05abf201cb1fb2bb4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0f677baa87c477db4e354feb97b02af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ec038a87124d4c008e6c9f1a8a1d1ed2",
              "IPY_MODEL_da886821f9bd48708461d95d8349fd21",
              "IPY_MODEL_17abce1fd4d2464faee509790239f23a"
            ],
            "layout": "IPY_MODEL_0e14d8e4abe448d99c48854c6cd30e8f"
          }
        },
        "ec038a87124d4c008e6c9f1a8a1d1ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dd237c1fb7f4913918a7d74bc729202",
            "placeholder": "​",
            "style": "IPY_MODEL_98327ed075194e01b71a10e9078379df",
            "value": "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: "
          }
        },
        "da886821f9bd48708461d95d8349fd21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc4184f15f2444ee825a0fbe3b649f9c",
            "max": 45749,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dba7c70d0074811b4a60c035f937963",
            "value": 45749
          }
        },
        "17abce1fd4d2464faee509790239f23a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4ceab97c7b44361ac0575c679d142e4",
            "placeholder": "​",
            "style": "IPY_MODEL_652647e98e6242138333147b0dc0bdb8",
            "value": " 367k/? [00:00&lt;00:00, 8.28MB/s]"
          }
        },
        "0e14d8e4abe448d99c48854c6cd30e8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3dd237c1fb7f4913918a7d74bc729202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98327ed075194e01b71a10e9078379df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc4184f15f2444ee825a0fbe3b649f9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dba7c70d0074811b4a60c035f937963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f4ceab97c7b44361ac0575c679d142e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "652647e98e6242138333147b0dc0bdb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}